{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from dotenv import dotenv_values\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('[tensorflow] GPU found')\n",
    "else:\n",
    "    print(\"[tensorflow] No GPU found\")\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from alpaca.trading.client import TradingClient\n",
    "from alpaca.trading.requests import MarketOrderRequest\n",
    "from alpaca.trading.enums import OrderSide, TimeInForce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Config\n",
    "BASE_URL = \"https://crabtrades.com\" \n",
    "\n",
    "SYMBOL = \"AAPL\" # example: NVDA, AAPL, META, AMD\n",
    "if not is_notebook() and len(sys.argv) > 1:\n",
    "    SYMBOL = sys.argv[1].upper()\n",
    "    print(SYMBOL)\n",
    "\n",
    "# Train Config\n",
    "TIME_FRAME = \"6Hour\"\n",
    "USE_SAVED_MODEL = False\n",
    "TEST_MODEL = True\n",
    "SHOULD_TRADE = False\n",
    "DOWNLOAD_DATASET = True\n",
    "RISK_PER_TRADE = 0.025\n",
    "MARKET_FIN_ID = \"US.NYSE\" # example: JP.JPX, US.NYSE\n",
    "\n",
    "# Traid Config\n",
    "# TIME_FRAME = \"6Hour\"\n",
    "# USE_SAVED_MODEL = True\n",
    "# TEST_MODEL = False\n",
    "# SHOULD_TRADE = True\n",
    "# DOWNLOAD_DATASET = True\n",
    "# RISK_PER_TRADE = 0.05\n",
    "# MARKET_FIN_ID = \"US.NYSE\" # example: JP.JPX, US.NYSE\n",
    "\n",
    "env_config = dotenv_values(\".env\")\n",
    "ADMIN_KEY = env_config[\"ADMIN_KEY\"]\n",
    "ALPACA_API_KEY = env_config[\"ALPACA_API_KEY\"]\n",
    "ALPACA_SECRET_KEY = env_config[\"ALPACA_SECRET_KEY\"]\n",
    "TRADINGHOURS_TOKEN = env_config[\"TRADINGHOURS_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_dataset():\n",
    "    current_utc_time = datetime.datetime.utcnow()\n",
    "    end_date = current_utc_time.strftime(\"%Y-%m-%d\") + \"T00:00:00.000Z\"\n",
    "    start_date = \"2016-01-01T00:00:00.000Z\"\n",
    "\n",
    "    if DOWNLOAD_DATASET or not Path('dataset.csv').is_file():\n",
    "        try:\n",
    "            response = requests.post(BASE_URL + \"/api/fetchHistoricalStock\", headers={\n",
    "                \"Enddate\": end_date,\n",
    "                \"Startdate\": start_date,\n",
    "                \"Symbol\": SYMBOL,\n",
    "                \"Timeframe\": TIME_FRAME,\n",
    "                \"admin-token\": ADMIN_KEY\n",
    "            })\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            raise SystemExit(f\"[/api/fetchHistoricalStock] Request error: {e}\")\n",
    "\n",
    "        if(response.status_code != 200):\n",
    "            print(response.text)\n",
    "            raise SystemExit(f\"[/api/fetchHistoricalStock] Repsonse status code: {response.status_code}\")\n",
    "\n",
    "        parsed_json = response.json()\n",
    "\n",
    "        df = pd.DataFrame(parsed_json)\n",
    "        df.to_csv('dataset.csv', index=False)\n",
    "        return df\n",
    "\n",
    "    return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = download_dataset()\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_prediction(df):\n",
    "    df = pd.read_csv('dataset.csv')\n",
    "    df.rename(columns={\n",
    "        \"ClosePrice\": \"Close\", \n",
    "        \"HighPrice\": \"High\", \n",
    "        \"LowPrice\": \"Low\", \n",
    "        \"OpenPrice\": \"Open\", \n",
    "        \"Timestamp\": \"Date\",\n",
    "        \"TradeCount\": \"Trades\"\n",
    "    }, inplace=True)\n",
    "    df.index = pd.to_datetime(df[\"Date\"])\n",
    "    df = df[[\"Open\", \"High\", \"Low\", \"Volume\", \"VWAP\", \"Trades\", \"Close\"]]\n",
    "\n",
    "    # https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "    pd.options.mode.copy_on_write = True\n",
    "\n",
    "    # Add running averages of 200 and 50 days\n",
    "    df.loc[:, '200MA'] = df['Close'].rolling(window=200).mean()\n",
    "    df.loc[:, '50MA'] = df['Close'].rolling(window=50).mean()\n",
    "    df = df.dropna()\n",
    "    df[[\"Open\", \"High\", \"Low\", \"Volume\", \"VWAP\", \"Trades\", \"200MA\", \"50MA\", \"Close\"]]\n",
    "    print(df.head(5))\n",
    "    \n",
    "    # Feature scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df[[\"Open\", \"High\", \"Low\", \"Volume\", \"VWAP\", \"Trades\", \"200MA\", \"50MA\", \"Close\"]])\n",
    "    scaled_data[10] # sequence_length. Take a look at last number, and y's first number\n",
    "\n",
    "    # Create sequences of data for input and target\n",
    "    def create_sequences(data, sequence_length):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            X.append(data[i:(i+sequence_length)])\n",
    "            y.append(data[i+sequence_length, 8])  # 6 corresponds to the 'Close' column\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    sequence_length = 10  # You can adjust this window size based on your needs\n",
    "    X, y = create_sequences(scaled_data, sequence_length)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    SPLIT = 0.9\n",
    "    split = int(SPLIT * len(X))\n",
    "    X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = None\n",
    "    fit_history = None\n",
    "    def init_model(use_saved_model: bool):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "        model.add(LSTM(units=50, activation='relu'))\n",
    "        model.add(Dense(units=1))\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        model.summary()\n",
    "\n",
    "        if use_saved_model and Path(\"model-\" + SYMBOL + \".keras\").exists() and Path(\"model-\" + SYMBOL + \".keras\").is_file():\n",
    "            # Load the model\n",
    "            model = tf.keras.models.load_model(\"model-\" + SYMBOL + \".keras\")\n",
    "        else:\n",
    "            # Train the model\n",
    "            fit_history = model.fit(X_train, y_train, epochs=25, batch_size=32, validation_split=0.1)\n",
    "            model.save(\"model-\" + SYMBOL + \".keras\")\n",
    "\n",
    "        # Evaluate the model on the test \n",
    "        if y_test.size != 0:\n",
    "            loss = model.evaluate(X_test, y_test)\n",
    "            print(f'Mean Squared Error on Test Set: {loss}')\n",
    "\n",
    "            # Predict future closes\n",
    "            predicted_closes = model.predict(X_test)\n",
    "\n",
    "        return model\n",
    "\n",
    "    should_buy = False\n",
    "    def predict_next():\n",
    "        # Use the last sequence_length days' data for tomorrow prediction\n",
    "        last_window = scaled_data[-sequence_length:]\n",
    "\n",
    "        # Reshape the data for prediction\n",
    "        last_window = last_window.reshape(1, sequence_length, last_window.shape[1])\n",
    "\n",
    "        # Make a prediction for the next day\n",
    "        predicted_close = model.predict(last_window)\n",
    "\n",
    "        # Inverse transform the prediction to get the actual closing price\n",
    "        predicted_close = scaler.inverse_transform(np.concatenate((last_window[:, -1, :-1], predicted_close.reshape(-1, 1)), axis=1))[:, -1]\n",
    "\n",
    "        # If price tommorow is bigger than today, we should buy\n",
    "        should_buy = predicted_close > df['Close'][df.index[-1]]\n",
    "\n",
    "        print(f'Predicted Close for the Next Day: {predicted_close[0]}')\n",
    "        print(f'Today: {df[\"Close\"][df.index[-1]]}')\n",
    "        print(f'Should buy: {should_buy}')\n",
    "        return should_buy\n",
    "\n",
    "    def test_model():\n",
    "        # Simulate trading\n",
    "        bought_counter = 0\n",
    "        sold_counter = 0\n",
    "        if TEST_MODEL:\n",
    "            predictions_df = pd.DataFrame(index=df.index, columns=['Actual Close', 'Predicted Close', \"BuySell\"])\n",
    "            print(\"Predicted: 0 / 0: 0\", end='')\n",
    "            for i in range(len(scaled_data) - 100, len(scaled_data)):\n",
    "                # Extract the last 10 days' data\n",
    "                window = scaled_data[i - sequence_length:i].reshape(1, sequence_length, scaled_data.shape[1])\n",
    "                \n",
    "                # Make a prediction\n",
    "                predicted_close = model.predict(window, verbose=0)\n",
    "                \n",
    "                # Inverse transform the prediction to get the actual closing price\n",
    "                predicted_close = scaler.inverse_transform(np.concatenate((window[:, -1, :-1], predicted_close.reshape(-1, 1)), axis=1))[:, -1]\n",
    "                \n",
    "                # Inverse transform the actual closing price\n",
    "                actual_close = scaler.inverse_transform(scaled_data[i:i+1])[:, -1]\n",
    "                \n",
    "                # Store the actual and predicted closes in the DataFrame\n",
    "                predictions_df.loc[df.index[i], 'Actual Close'] = actual_close[0]\n",
    "                predictions_df.loc[df.index[i], 'Predicted Close'] = predicted_close[0]\n",
    "\n",
    "                print(f'\\rPredicted: {i} / {len(scaled_data)}: {predicted_close[0]}', end='')\n",
    "\n",
    "                predictions_df.loc[df.index[i], 'BuySell'] = \"Hold\"\n",
    "                \n",
    "                yesterday_close = predictions_df.loc[df.index[i - 1], 'Actual Close']\n",
    "\n",
    "                # Check if 'yesterday_close' is a Pandas Series (indicating duplicate timestamps)\n",
    "                if isinstance(yesterday_close, pd.Series):\n",
    "                    # Use the first value, but you might need a different strategy based on your data\n",
    "                    yesterday_close = yesterday_close.iloc[0]\n",
    "\n",
    "                # Check if 'yesterday_close' is NaN or a valid number\n",
    "                if pd.isna(yesterday_close):\n",
    "                    continue\n",
    "                    \n",
    "                predictions_df.loc[df.index[i], 'BuySell'] = \"Sell\" if predicted_close[0] < yesterday_close else \"Buy\"\n",
    "                \n",
    "            # Count the number of buy and sell signals\n",
    "            print('\\n')\n",
    "            bought_counter = len(predictions_df[predictions_df['BuySell'] == \"Buy\"])\n",
    "            sold_counter = len(predictions_df[predictions_df['BuySell'] == \"Sell\"])\n",
    "            print(f\"Bought: {bought_counter}, Sold: {sold_counter}\")\n",
    "\n",
    "            # Error of the model\n",
    "            loss = model.evaluate(X_test, y_test)\n",
    "            print(f'Mean Squared Error on Test Set: {loss}')\n",
    "\n",
    "        if is_notebook():\n",
    "            # Plot the model' training loss\n",
    "            if fit_history is not None:\n",
    "                plt.plot(fit_history.history[\"loss\"][3:], label='Training Loss')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "            # Evaluate the model on the test \n",
    "            if y_test.size != 0:\n",
    "                # Predict future closes\n",
    "                predicted_closes = model.predict(X_test)\n",
    "                plt.plot(df.index[-len(y_test):], y_test, label='True Close Prices', c='b')\n",
    "                plt.plot(df.index[-len(y_test):], predicted_closes, label='Predicted Close Prices', c='r')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                \n",
    "            if TEST_MODEL:\n",
    "                # Plot the actual and predicted closes\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                plt.plot(predictions_df.index, predictions_df['Predicted Close'], label='Predicted Close', color=\"skyblue\")\n",
    "                plt.plot(predictions_df.index, predictions_df['Actual Close'], label='Actual Close', color=\"blue\")\n",
    "\n",
    "                buy_points = predictions_df[predictions_df['BuySell'] == 'Buy']\n",
    "                sell_points = predictions_df[predictions_df['BuySell'] == 'Sell']\n",
    "                hold_points = predictions_df[predictions_df['BuySell'] == 'Hold']\n",
    "\n",
    "                plt.scatter(buy_points.index, buy_points['Actual Close'], color='green', marker='o', label='Buy')\n",
    "                plt.scatter(sell_points.index, sell_points['Actual Close'], color='red', marker='o', label='Sell')\n",
    "                plt.scatter(hold_points.index, hold_points['Actual Close'], color='gray', marker='o', label='Hold')\n",
    "                plt.title('Actual vs Predicted Closes')\n",
    "                plt.xlabel('Date')\n",
    "                plt.ylabel('Close Price')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "        is_right_model = bought_counter > 14 and sold_counter > 14\n",
    "        return is_right_model\n",
    "\n",
    "    if TEST_MODEL:\n",
    "        for i in range(20):\n",
    "            model = init_model(False)\n",
    "            if test_model():\n",
    "                break\n",
    "    else:\n",
    "        model = init_model(USE_SAVED_MODEL)\n",
    "\n",
    "    should_buy = predict_next()\n",
    "\n",
    "    return should_buy, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_buy, df = make_prediction(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_market_open(symbol):\n",
    "    try:\n",
    "        TRADINGHOURS_URL = \"https://api.tradinghours.com/v3/markets/status\"\n",
    "        response = requests.get(TRADINGHOURS_URL, params={\n",
    "            \"fin_id\": symbol,\n",
    "            \"api_token\": TRADINGHOURS_TOKEN\n",
    "        })\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise SystemExit(f\"[/api/fetchHistoricalStock] Request error: {e}\")\n",
    "\n",
    "    if(response.status_code != 200):\n",
    "        raise SystemExit(f\"[/api/fetchHistoricalStock] Repsonse status code: {response.status_code}\")\n",
    "    \n",
    "    return response.json()[\"data\"][symbol.upper()][\"status\"] == \"Open\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_market_open(MARKET_FIN_ID):\n",
    "    raise SystemExit(f\"[TradingHours] Market {MARKET_FIN_ID} is closed\")\n",
    "\n",
    "print(f\"[TradingHours] Market {MARKET_FIN_ID} is open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trade_alpaca(should_buy, df):\n",
    "    # Calculate the True Range (TR)\n",
    "    df['High-Low'] = df['High'] - df['Low']\n",
    "    df['High-Close-Prev'] = abs(df['High'] - df['Close'].shift(1))\n",
    "    df['Low-Close-Prev'] = abs(df['Low'] - df['Close'].shift(1))\n",
    "    df['True Range'] = df[['High-Low', 'High-Close-Prev', 'Low-Close-Prev']].max(axis=1)\n",
    "\n",
    "    # Calculate the ATR for the last day in the dataset without using a rolling average\n",
    "    ATR = df['True Range'].tail(14).mean()\n",
    "\n",
    "    # Drop intermediate columns used for calculations\n",
    "    data = df.drop(['High-Low', 'High-Close-Prev', 'Low-Close-Prev', 'True Range'], axis=1)\n",
    "\n",
    "    trading_client = TradingClient(ALPACA_API_KEY, ALPACA_SECRET_KEY, paper=True)\n",
    "\n",
    "    account = trading_client.get_account()\n",
    "    if account.trading_blocked:\n",
    "        raise SystemExit(\"[Alpaca] Account is currently restricted from trading.\")\n",
    "\n",
    "    asset = trading_client.get_asset(SYMBOL)\n",
    "    if not asset.tradable:\n",
    "        raise SystemExit(\"[Alpaca] The requested asset is not tradable.\")\n",
    "\n",
    "    # Get current price of the stock\n",
    "    all_positions = trading_client.get_all_positions()\n",
    "    traded_position = None\n",
    "\n",
    "    for position in all_positions:\n",
    "        if position.symbol == SYMBOL:\n",
    "            traded_position = position\n",
    "            break\n",
    "\n",
    "    last_price = df['Close'][df.index[-1]]\n",
    "    current_quantity = 0\n",
    "    if traded_position != None:\n",
    "        last_price = float(traded_position.current_price)\n",
    "        current_quantity = float(traded_position.qty)\n",
    "\n",
    "    decision = \"BUY\" if should_buy else \"SELL\"\n",
    "\n",
    "    # Volatility-based Position Sizing\n",
    "    # Risk per Trade is the percentage of capital you are willing to risk on the trade.\n",
    "    # ATR is the Average True Range, a measure of volatility.\n",
    "    trade_quantity = RISK_PER_TRADE * float(account.portfolio_value) / ATR / last_price\n",
    "\n",
    "    # Trade as much, as I can\n",
    "    if decision == \"SELL\":\n",
    "        trade_quantity = min(current_quantity, trade_quantity) \n",
    "\n",
    "    if SHOULD_TRADE:\n",
    "        if (should_buy and float(account.buying_power) > last_price) or (not should_buy and current_quantity > 0):\n",
    "            # preparing market order\n",
    "            market_order_data = MarketOrderRequest(\n",
    "                symbol=SYMBOL,\n",
    "                qty=trade_quantity,\n",
    "                side= OrderSide.BUY if should_buy else OrderSide.SELL,\n",
    "                time_in_force=TimeInForce.DAY\n",
    "            )\n",
    "\n",
    "            # Market order\n",
    "            market_order = trading_client.submit_order(\n",
    "                order_data=market_order_data\n",
    "            )\n",
    "        else:\n",
    "            print(\"Not enough buying power/quantity to trade.\")\n",
    "            decision = \"HOLD\"\n",
    "    else:\n",
    "        raise SystemExit(\"[Config] SHOULD_TRADE = False\")\n",
    "\n",
    "    return account, trade_quantity, decision, last_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_account, trade_quantity, decision, last_price = trade_alpaca(should_buy, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_to_firestore(alpaca_account, trade_quantity, decision, last_price):\n",
    "    portfolio_value = alpaca_account.portfolio_value\n",
    "    date = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "    print(f\"Date: {date}\")\n",
    "    print(f\"Budget: {portfolio_value}\")\n",
    "    print(f\"Quantity: {trade_quantity}\")\n",
    "    print(f\"Decision: {decision}\")\n",
    "    print(f\"Last Price: {last_price}\")\n",
    "\n",
    "    try:\n",
    "        response = requests.post(BASE_URL + \"/api/firestore\", headers = {\n",
    "            \"symbol\": SYMBOL,\n",
    "            \"date\": date,\n",
    "            \"portfolioValue\": portfolio_value,\n",
    "            \"quantity\": str(trade_quantity),\n",
    "            \"decision\": decision,\n",
    "            # \"lastPrice\": last_price,\n",
    "            \"admin-token\": ADMIN_KEY\n",
    "        })\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise SystemExit(f\"[/api/firestore] Request error: {e}\")\n",
    "\n",
    "    if(response.status_code != 200):\n",
    "        raise SystemExit(f\"[/api/firestore] Repsonse status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_to_firestore(alpaca_account, trade_quantity, decision, last_price)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
